{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "# sc=SparkContext('local') this didn't work\n",
    "# sc = ps.SparkContext('local[4]') this didn't work\n",
    "sqlContext = ps.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- Accepts Credit Cards: string (nullable = true)\n",
      " |    |-- Accepts Insurance: boolean (nullable = true)\n",
      " |    |-- Ages Allowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: struct (nullable = true)\n",
      " |    |    |-- casual: boolean (nullable = true)\n",
      " |    |    |-- classy: boolean (nullable = true)\n",
      " |    |    |-- divey: boolean (nullable = true)\n",
      " |    |    |-- hipster: boolean (nullable = true)\n",
      " |    |    |-- intimate: boolean (nullable = true)\n",
      " |    |    |-- romantic: boolean (nullable = true)\n",
      " |    |    |-- touristy: boolean (nullable = true)\n",
      " |    |    |-- trendy: boolean (nullable = true)\n",
      " |    |    |-- upscale: boolean (nullable = true)\n",
      " |    |-- Attire: string (nullable = true)\n",
      " |    |-- BYOB: boolean (nullable = true)\n",
      " |    |-- BYOB/Corkage: string (nullable = true)\n",
      " |    |-- By Appointment Only: boolean (nullable = true)\n",
      " |    |-- Caters: boolean (nullable = true)\n",
      " |    |-- Coat Check: boolean (nullable = true)\n",
      " |    |-- Corkage: boolean (nullable = true)\n",
      " |    |-- Delivery: boolean (nullable = true)\n",
      " |    |-- Dietary Restrictions: struct (nullable = true)\n",
      " |    |    |-- dairy-free: boolean (nullable = true)\n",
      " |    |    |-- gluten-free: boolean (nullable = true)\n",
      " |    |    |-- halal: boolean (nullable = true)\n",
      " |    |    |-- kosher: boolean (nullable = true)\n",
      " |    |    |-- soy-free: boolean (nullable = true)\n",
      " |    |    |-- vegan: boolean (nullable = true)\n",
      " |    |    |-- vegetarian: boolean (nullable = true)\n",
      " |    |-- Dogs Allowed: boolean (nullable = true)\n",
      " |    |-- Drive-Thru: boolean (nullable = true)\n",
      " |    |-- Good For: struct (nullable = true)\n",
      " |    |    |-- breakfast: boolean (nullable = true)\n",
      " |    |    |-- brunch: boolean (nullable = true)\n",
      " |    |    |-- dessert: boolean (nullable = true)\n",
      " |    |    |-- dinner: boolean (nullable = true)\n",
      " |    |    |-- latenight: boolean (nullable = true)\n",
      " |    |    |-- lunch: boolean (nullable = true)\n",
      " |    |-- Good For Dancing: boolean (nullable = true)\n",
      " |    |-- Good For Groups: boolean (nullable = true)\n",
      " |    |-- Good For Kids: boolean (nullable = true)\n",
      " |    |-- Good for Kids: boolean (nullable = true)\n",
      " |    |-- Hair Types Specialized In: struct (nullable = true)\n",
      " |    |    |-- africanamerican: boolean (nullable = true)\n",
      " |    |    |-- asian: boolean (nullable = true)\n",
      " |    |    |-- coloring: boolean (nullable = true)\n",
      " |    |    |-- curly: boolean (nullable = true)\n",
      " |    |    |-- extensions: boolean (nullable = true)\n",
      " |    |    |-- kids: boolean (nullable = true)\n",
      " |    |    |-- perms: boolean (nullable = true)\n",
      " |    |    |-- straightperms: boolean (nullable = true)\n",
      " |    |-- Happy Hour: boolean (nullable = true)\n",
      " |    |-- Has TV: boolean (nullable = true)\n",
      " |    |-- Music: struct (nullable = true)\n",
      " |    |    |-- background_music: boolean (nullable = true)\n",
      " |    |    |-- dj: boolean (nullable = true)\n",
      " |    |    |-- jukebox: boolean (nullable = true)\n",
      " |    |    |-- karaoke: boolean (nullable = true)\n",
      " |    |    |-- live: boolean (nullable = true)\n",
      " |    |    |-- playlist: boolean (nullable = true)\n",
      " |    |    |-- video: boolean (nullable = true)\n",
      " |    |-- Noise Level: string (nullable = true)\n",
      " |    |-- Open 24 Hours: boolean (nullable = true)\n",
      " |    |-- Order at Counter: boolean (nullable = true)\n",
      " |    |-- Outdoor Seating: boolean (nullable = true)\n",
      " |    |-- Parking: struct (nullable = true)\n",
      " |    |    |-- garage: boolean (nullable = true)\n",
      " |    |    |-- lot: boolean (nullable = true)\n",
      " |    |    |-- street: boolean (nullable = true)\n",
      " |    |    |-- valet: boolean (nullable = true)\n",
      " |    |    |-- validated: boolean (nullable = true)\n",
      " |    |-- Payment Types: struct (nullable = true)\n",
      " |    |    |-- amex: boolean (nullable = true)\n",
      " |    |    |-- cash_only: boolean (nullable = true)\n",
      " |    |    |-- discover: boolean (nullable = true)\n",
      " |    |    |-- mastercard: boolean (nullable = true)\n",
      " |    |    |-- visa: boolean (nullable = true)\n",
      " |    |-- Price Range: long (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- Take-out: boolean (nullable = true)\n",
      " |    |-- Takes Reservations: boolean (nullable = true)\n",
      " |    |-- Waiter Service: boolean (nullable = true)\n",
      " |    |-- Wheelchair Accessible: boolean (nullable = true)\n",
      " |    |-- Wi-Fi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- full_address: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Monday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Saturday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Sunday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Thursday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Tuesday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Wednesday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighborhoods: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- open: boolean (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the Yelp business data using the function `.read.json()` from the `SparkSession()` object with input file.\n",
    "df = sqlContext.read.json('data/yelp_academic_dataset_business.json.gz')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------+--------------------+--------------------+---------+-----------+-----------------+-------------+----+------------+-----+-----+--------+\n",
      "|          attributes|         business_id|          categories|   city|        full_address|               hours| latitude|  longitude|             name|neighborhoods|open|review_count|stars|state|    type|\n",
      "+--------------------+--------------------+--------------------+-------+--------------------+--------------------+---------+-----------+-----------------+-------------+----+------------+-----+-----+--------+\n",
      "|[null,null,null,n...|vcNAWiLM4dR7D2nww...|[Doctors, Health ...|Phoenix|4840 E Indian Sch...|[[17:00,08:00],[1...|33.499313|-111.983758|Eric Goldberg, MD|           []|true|           9|  3.5|   AZ|business|\n",
      "+--------------------+--------------------+--------------------+-------+--------------------+--------------------+---------+-----------+-----------------+-------------+----+------------+-----+-----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>full_address</th>\n",
       "      <th>hours</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhoods</th>\n",
       "      <th>open</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "      <td>[Doctors, Health &amp; Medical]</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ ...</td>\n",
       "      <td>((17:00, 08:00), (17:00, 08:00), None, None, (...</td>\n",
       "      <td>33.499313</td>\n",
       "      <td>-111.983758</td>\n",
       "      <td>Eric Goldberg, MD</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>AZ</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(true, None, None, None, None, None, None, Non...</td>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>[Nightlife]</td>\n",
       "      <td>Dravosburg</td>\n",
       "      <td>202 McClure St\\nDravosburg, PA 15034</td>\n",
       "      <td>(None, None, None, None, None, None, None)</td>\n",
       "      <td>40.350519</td>\n",
       "      <td>-79.886930</td>\n",
       "      <td>Clancy's Pub</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>[Active Life, Mini Golf, Golf]</td>\n",
       "      <td>Bethel Park</td>\n",
       "      <td>1530 Hamilton Rd\\nBethel Park, PA 15234</td>\n",
       "      <td>(None, None, None, None, None, None, None)</td>\n",
       "      <td>40.356896</td>\n",
       "      <td>-80.015910</td>\n",
       "      <td>Cool Springs Golf Center</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>HZdLhv6COCleJMo7nPl-RA</td>\n",
       "      <td>[Shopping, Home Services, Internet Service Pro...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>301 S Hills Vlg\\nPittsburgh, PA 15241</td>\n",
       "      <td>((21:00, 10:00), (21:00, 10:00), (21:00, 10:00...</td>\n",
       "      <td>40.357620</td>\n",
       "      <td>-80.059980</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(true, None, None, full_bar, (False, False, Fa...</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>[Bars, American (New), Nightlife, Lounges, Res...</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>414 Hawkins Ave\\nBraddock, PA 15104</td>\n",
       "      <td>((20:00, 10:00), None, (16:00, 10:00), None, (...</td>\n",
       "      <td>40.408735</td>\n",
       "      <td>-79.866351</td>\n",
       "      <td>Emil's Lounge</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          attributes             business_id  \\\n",
       "0  (None, None, None, None, None, None, None, Non...  vcNAWiLM4dR7D2nwwJ7nCA   \n",
       "1  (true, None, None, None, None, None, None, Non...  UsFtqoBl7naz8AVUBZMjQQ   \n",
       "2  (None, None, None, None, None, None, None, Non...  cE27W9VPgO88Qxe4ol6y_g   \n",
       "3  (None, None, None, None, None, None, None, Non...  HZdLhv6COCleJMo7nPl-RA   \n",
       "4  (true, None, None, full_bar, (False, False, Fa...  mVHrayjG3uZ_RLHkLj-AMg   \n",
       "\n",
       "                                          categories         city  \\\n",
       "0                        [Doctors, Health & Medical]      Phoenix   \n",
       "1                                        [Nightlife]   Dravosburg   \n",
       "2                     [Active Life, Mini Golf, Golf]  Bethel Park   \n",
       "3  [Shopping, Home Services, Internet Service Pro...   Pittsburgh   \n",
       "4  [Bars, American (New), Nightlife, Lounges, Res...     Braddock   \n",
       "\n",
       "                                        full_address  \\\n",
       "0  4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ ...   \n",
       "1               202 McClure St\\nDravosburg, PA 15034   \n",
       "2            1530 Hamilton Rd\\nBethel Park, PA 15234   \n",
       "3              301 S Hills Vlg\\nPittsburgh, PA 15241   \n",
       "4                414 Hawkins Ave\\nBraddock, PA 15104   \n",
       "\n",
       "                                               hours   latitude   longitude  \\\n",
       "0  ((17:00, 08:00), (17:00, 08:00), None, None, (...  33.499313 -111.983758   \n",
       "1         (None, None, None, None, None, None, None)  40.350519  -79.886930   \n",
       "2         (None, None, None, None, None, None, None)  40.356896  -80.015910   \n",
       "3  ((21:00, 10:00), (21:00, 10:00), (21:00, 10:00...  40.357620  -80.059980   \n",
       "4  ((20:00, 10:00), None, (16:00, 10:00), None, (...  40.408735  -79.866351   \n",
       "\n",
       "                       name neighborhoods   open  review_count  stars state  \\\n",
       "0         Eric Goldberg, MD            []   True             9    3.5    AZ   \n",
       "1              Clancy's Pub            []   True             4    3.5    PA   \n",
       "2  Cool Springs Golf Center            []  False             5    2.5    PA   \n",
       "3          Verizon Wireless            []   True             3    3.5    PA   \n",
       "4             Emil's Lounge            []   True            11    4.5    PA   \n",
       "\n",
       "       type  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.toPandas()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+--------------------+-----+\n",
      "|                name|       city|state|          attributes|stars|\n",
      "+--------------------+-----------+-----+--------------------+-----+\n",
      "|   Eric Goldberg, MD|    Phoenix|   AZ|[null,null,null,n...|  3.5|\n",
      "|        Clancy's Pub| Dravosburg|   PA|[true,null,null,n...|  3.5|\n",
      "|Cool Springs Golf...|Bethel Park|   PA|[null,null,null,n...|  2.5|\n",
      "|    Verizon Wireless| Pittsburgh|   PA|[null,null,null,n...|  3.5|\n",
      "|       Emil's Lounge|   Braddock|   PA|[true,null,null,f...|  4.5|\n",
      "|Alexion's Bar & G...|   Carnegie|   PA|[true,null,null,f...|  4.0|\n",
      "|Flynn's E W Tire ...|   Carnegie|   PA|[null,null,null,n...|  1.5|\n",
      "|Forsythe Miniatur...|   Carnegie|   PA|[null,null,null,n...|  4.0|\n",
      "|Quaker State Cons...|   Carnegie|   PA|[null,null,null,n...|  2.5|\n",
      "|Kings Family Rest...|   Carnegie|   PA|[true,null,null,n...|  3.5|\n",
      "+--------------------+-----------+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Register the dataframe as a temporary table named yelp_business (this will enable us to query the table later using our SparkSession() object).\n",
    "df.createOrReplaceTempView(\"yelp_business\")\n",
    "#yelp_business=spark.table(\"yelp_business_df\")\n",
    "result = spark.sql(\"SELECT name, city, state, attributes, stars FROM yelp_business LIMIT 10\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Panini Bread and Grill'),\n",
       " Row(name='Gluten Free Creations Bakery'),\n",
       " Row(name='Ten Handcrafted American Fare & Spirits'),\n",
       " Row(name='One Eighty Q'),\n",
       " Row(name='Subway'),\n",
       " Row(name='Banh Mi Bistro Vietnamese Eatery'),\n",
       " Row(name='Tacos Huicho'),\n",
       " Row(name='Helpings Cafe, Market and Catering'),\n",
       " Row(name='Sunfare'),\n",
       " Row(name=\"Bertie's Of Arcadia\"),\n",
       " Row(name='Los Primos Carniceria'),\n",
       " Row(name='The Brown Bag'),\n",
       " Row(name='Little Miss BBQ'),\n",
       " Row(name='Auslers Grill'),\n",
       " Row(name=\"Adela's Italian\"),\n",
       " Row(name='Coe Casa'),\n",
       " Row(name='Altamimi Restutant'),\n",
       " Row(name='Las Jicaras Mexican Grill'),\n",
       " Row(name='Queen Creek Olive Mill Oils & Olives Biltmore Fashion Park'),\n",
       " Row(name='Saffron JAK Original Stonebread Pizzas'),\n",
       " Row(name='Couscous Express'),\n",
       " Row(name='The Loaded Potato'),\n",
       " Row(name='Santos Lucha Libre'),\n",
       " Row(name=\"Mulligan's Restaurant\"),\n",
       " Row(name='Taqueria El Chino'),\n",
       " Row(name=\"Jimmy John's\"),\n",
       " Row(name=\"Lil Cal's\"),\n",
       " Row(name='Frenchys Caribbean Dogs'),\n",
       " Row(name=\"Ed's\"),\n",
       " Row(name=\"Filiberto's Mexican Food\"),\n",
       " Row(name='Pollo Sabroso'),\n",
       " Row(name='WY Market')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a query or a sequence of transformations that returns the name of entries that fulfill the following conditions:\n",
    "# Rated at 5 stars\n",
    "# In the city of Phoenix\n",
    "# Accepts credit card (Reference the 'Accepts Credit Card' field by  attributes.`Accepts Credit Cards`. NOTE: We are actually looking for the value 'true', not the boolean value True!)\n",
    "# Contains Restaurants in the categories array. Hint: LATERAL VIEW explode() Hint: In spark, while using filter() or where()\n",
    "r1=spark.sql(\"select name FROM yelp_business WHERE city = 'Phoenix' AND stars = 5\")\n",
    "#r1.show()\n",
    "\n",
    "#using pyspark\n",
    "from pyspark.sql.functions import col, array_contains\n",
    "yelp_business_df.filter((col('stars') == 5) &\n",
    "                        (col('city') == 'Phoenix') &\n",
    "                        (col('attributes.`Accepts Credit Cards`') == 'true') &\n",
    "                        (array_contains(col('categories'),'Restaurants'))).select('name').collect()\n",
    "\n",
    "#using spark.sql\n",
    "spark.sql(\"\"\"SELECT DISTINCT name from yelp_business\n",
    "                   LATERAL VIEW explode(categories) AS category\n",
    "                   WHERE stars = 5 \n",
    "                   AND city = 'Phoenix'\n",
    "                   AND attributes.`Accepts Credit Cards` = 'true'\n",
    "                   AND category = 'Restaurants'\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1106214172, name='Prometheus Barwis', email='prometheus.barwis@me.com', phone='(533) 072-2779'),\n",
       " Row(id=527133132, name='Ashraf Bainbridge', email='ashraf.bainbridge@gmail.com', phone=None),\n",
       " Row(id=1290614884, name='Alain Hennesey', email='alain.hennesey@facebook.com,alain.hennesey@me.com', phone='(942) 208-8460,(801) 938-2376'),\n",
       " Row(id=1700818057, name='Hamed Fingerhuth', email='hamed.fingerhuth@msn.com,hamed.fingerhuth@me.com', phone=None),\n",
       " Row(id=17378782, name='Annamae Leyte', email='annamae.leyte@msn.com,annamae.leyte@facebook.com', phone=None)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataframe users from S3 link ''s3a://sparkdatasets/users.txt' (no credentials needed but if you encounter any problem just use local copy data/users.txt instead) using spark.read.csv with the following parameters: no headers, use separator \";\", and infer the schema of the underlying data (for now). Use .show(5) and .printSchema() to check the result.\n",
    "# Create a schema for this dataset using proper names and types for the columns, using types from the pyspark.sql.types module (see lecture). Use that schema to read the users dataframe again and use .printSchema() to check the result.\n",
    "# Note: Each row in the users file represents the user with his/her user_id, name, email, phone.\n",
    "\n",
    "    users_schema = StructType( [\n",
    "    StructField('id',IntegerType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('email',StringType(),True),\n",
    "    StructField('phone',StringType(),True) ] )\n",
    "# reading the file using SparkContext\n",
    "users = spark.read.csv('data/users.txt',\n",
    "                         header=False,       # use headers or not\n",
    "                         quote='\"',         # char for quotes\n",
    "                         sep=\";\",           # char for separation\n",
    "                         schema=users_schema, # using predefined schema\n",
    "                         inferSchema=False)  \n",
    "#rdd = sc.textFile('data/users.txt')\n",
    "users.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "transactions_rdd=sc.textFile('data/transactions.txt')\n",
    "print(type(transactions_rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['815581247;$144.82;2015-09-05',\n",
       " '1534673027;$140.93;2014-03-11',\n",
       " '842468364;$104.26;2014-05-06',\n",
       " '1720001139;$194.60;2015-08-24',\n",
       " '1397891675;$307.72;2015-09-25']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def casting_function(trans_id, amount, date):\n",
    "    return(int(trans_id), float(amount), date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(815581247, 144.82, '2015-09-05'),\n",
       " (1534673027, 140.93, '2014-03-11'),\n",
       " (842468364, 104.26, '2014-05-06'),\n",
       " (1720001139, 194.6, '2015-08-24'),\n",
       " (1397891675, 307.72, '2015-09-25')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an RDD transactions_rdd from S3 link ''s3a://sparkdatasets/transactions.txt' (no credentials needed but if you encounter any problem just use local copy data/transactions.txt instead) using spark.sparkContext.textFile. Use .take(5) to check the result.\n",
    "# Use .map() to split those csv-like lines, to strip the dollar sign on the second column, and to cast each column to its proper type.\n",
    "\n",
    "df_schema = StructType([StructField('id',StringType(),True),StructField('amount',FloatType(),True),StructField('date',StringType(),True)])\n",
    "rdd_trans = spark.sparkContext.textFile('data/transactions.txt').map(lambda s : s.split(';')).map(lambda row : (int(row[0]),float(row[1].lstrip(\"$\")),row[2]))\n",
    "#.filter(lambda x: not x[0].startswith('$'))\n",
    "#.map(lambda x : x.split())\n",
    "rdd_trans.collect()\n",
    "rdd_trans.take(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a schema for this dataset using proper names and types for the columns, using types from the pyspark.sql.types module (see lecture). Use that schema to convert transactions_rdd into a dataframe transactions and use .show(5) and .printSchema() to check the result.\n",
    "# Each row in the transactions file has the columns  user_id, amount_paid, date.\n",
    "schema = StructType([StructField('id',StringType(),True),StructField('amount',FloatType(),True),StructField('date',StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- amount: float (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n",
      "+----------+------+----------+\n",
      "|        id|amount|      date|\n",
      "+----------+------+----------+\n",
      "| 815581247|144.82|2015-09-05|\n",
      "|1534673027|140.93|2014-03-11|\n",
      "| 842468364|104.26|2014-05-06|\n",
      "|1720001139| 194.6|2015-08-24|\n",
      "|1397891675|307.72|2015-09-25|\n",
      "| 926282663| 36.69|2014-10-24|\n",
      "| 694853136| 39.59|2014-11-26|\n",
      "| 636287877|430.94|2015-06-12|\n",
      "|1396310477|  31.4|2014-12-05|\n",
      "|1279939289|180.69|2015-03-26|\n",
      "| 859061953|383.35|2014-06-06|\n",
      "|1983919868| 256.2|2015-09-28|\n",
      "| 589339046|930.56|2014-09-21|\n",
      "|1559785598|423.77|2015-05-18|\n",
      "| 347589978|309.53|2015-10-11|\n",
      "| 963722938|299.19|2014-04-06|\n",
      "|1808365853|426.21|2015-09-10|\n",
      "| 417552135|732.27|2015-09-30|\n",
      "| 744965566|186.33|2015-12-30|\n",
      "|1513020241| 925.8|2014-10-06|\n",
      "+----------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_trans= sqlContext.createDataFrame(rdd_trans,schema)\n",
    "df_trans = sqlContext.createDataFrame(rdd_trans, schema)\n",
    "df_trans.printSchema()\n",
    "df_trans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Raziel Merk', amount=999.989990234375),\n",
       " Row(name='Andrian Waite', amount=999.989990234375),\n",
       " Row(name='Kianu Dyneley', amount=999.989990234375),\n",
       " Row(name='Landri Fulshur', amount=999.989990234375),\n",
       " Row(name='Leilani Cranstoun', amount=999.97998046875),\n",
       " Row(name='Samyrah Milbourne', amount=999.97998046875),\n",
       " Row(name='Vishwak Farrow', amount=999.97998046875),\n",
       " Row(name='Veida Hubbard', amount=999.97998046875),\n",
       " Row(name='Ori Horrage', amount=999.97998046875),\n",
       " Row(name='Zasia Scrivens', amount=999.97998046875)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a sequence of transformations or a SQL query that returns the names and the amount paid for the users with the top 10 transaction amounts.\n",
    "users.createOrReplaceTempView('users')\n",
    "df_trans.createOrReplaceTempView('transactions')\n",
    "\n",
    "r1=spark.sql(\"\"\"select users.name, trans.amount FROM \n",
    "             (SELECT * FROM transactions ORDER BY amount DESC LIMIT 10) trans\n",
    "             JOIN users\n",
    "             ON users.id = trans.id\"\"\").collect()\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
